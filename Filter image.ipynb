{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f181e-775e-4d72-8bc4-6de756555626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "# !pip install opencv-python-headless\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam, legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18e5c1-3e44-4fa5-9d6f-a15f1b90df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSVs and filter by Labeling State\n",
    "csv_files = {\n",
    "    \"EPH\": 'Hemorrhage Segmentation Project/Results_Epidural Hemorrhage Detection_2020-11-16_21.31.26.148.csv',\n",
    "    \"IVH\": 'Hemorrhage Segmentation Project/Results_Brain Hemorrhage Tracing_2020-09-28_15.21.52.597.csv',\n",
    "    \"IPH\": 'Hemorrhage Segmentation Project/Results_Intraparenchymal Hemorrhage Detection_2020-11-16_21.39.31.268.csv',\n",
    "    \"SDH\": 'Hemorrhage Segmentation Project/Results_Subdural Hemorrhage Detection_2020-11-16_21.37.19.745.csv',\n",
    "    \"SAH\": 'Hemorrhage Segmentation Project/Results_Subarachnoid Hemorrhage Detection_2020-11-16_21.36.18.668.csv',\n",
    "    \"MCH\": 'Hemorrhage Segmentation Project/Results_Multiple Hemorrhage Detection_2020-11-16_21.36.24.018.csv'\n",
    "}\n",
    "\n",
    "filtered_files = {}\n",
    "for key, csv_file in csv_files.items():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df_filtered = df[df['Labeling State'].isin(['Labeled', 'Gold Standard'])]\n",
    "    filtered_files[key] = set(df_filtered['Origin'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08810a42-333c-428a-92d5-29450f10a411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_dir = 'XN1 Data/renders/' \n",
    "ICH_types = ['normal', 'epidural', 'subarachnoid', 'intraparenchymal', 'subdural', 'intraventricular', 'multi']\n",
    "windows = [\"brain_bone_window\", \"brain_window\", \"max_contrast_window\", \"subdural_window\"]\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[0], [1], [2], [3], [4], [5], [6]])\n",
    "target_shape = (512, 512, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a25b4d-7fd8-4679-a90c-2850fc9a4a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_directory(directory, label, target_shape, file_max=None, filter_set=None):\n",
    "    \"\"\"Load images from a given directory, check shape, and apply one-hot encoding.\"\"\"\n",
    "    train_data = []\n",
    "    filenames = os.listdir(directory)\n",
    "    if file_max is None:\n",
    "        file_max = len(filenames)\n",
    "\n",
    "    true_file_max = file_max\n",
    "\n",
    "    for filename in tqdm(filenames[0:file_max], desc=f'Loading images from {directory}', unit='file'):\n",
    "        if filter_set and filename not in filter_set:\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Convert to array and check shape\n",
    "        img_np = np.array(img)\n",
    "        if img_np.shape != target_shape:\n",
    "            img = img.resize((512, 512), Image.LANCZOS)  # Resize to match target shape\n",
    "\n",
    "        img = img.resize((256, 256), Image.LANCZOS)  # Downsample to 256x256\n",
    "        img_array = np.array(img)\n",
    "        grayscale_img = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "        train_data.append(grayscale_img)\n",
    "\n",
    "    return train_data, len(train_data)\n",
    "\n",
    "\n",
    "def main_loader(directory, windows, label, X_train_dict, y_train, target_shape, file_max=None, filter_set=None):\n",
    "    for slide in windows:\n",
    "        dir_path = os.path.join(directory, ICH_types[label], slide)\n",
    "        print(f\"Loading images for {slide}...\")\n",
    "        data, _ = load_images_from_directory(dir_path, label, target_shape, file_max, filter_set)\n",
    "        X_train_dict[slide].extend(data)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    print(\"Converting lists to numpy arrays:\")\n",
    "    for window in tqdm(windows, desc='Converting lists', unit='window'):\n",
    "        X_train_dict[window] = np.array(X_train_dict[window])\n",
    "\n",
    "    sample = encoder.transform([[label]]).toarray()\n",
    "    labels = np.tile(sample, (len(data), 1))\n",
    "    y_train = np.array(labels)\n",
    "\n",
    "    return X_train_dict, y_train\n",
    "\n",
    "\n",
    "def stack_slices(X_train_dict):\n",
    "    windows_to_stack = [\n",
    "        'brain_bone_window', \n",
    "        'brain_window', \n",
    "        'subdural_window', \n",
    "        'max_contrast_window'\n",
    "    ]\n",
    "    stacked_data = []\n",
    "    for window in tqdm(windows_to_stack, desc='Stacking slices', unit='window'):\n",
    "        stacked_data.append(X_train_dict[window])\n",
    "    X_train = np.stack(stacked_data, axis=3)\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ddd6e8-31f0-4472-afb6-ef51b17c7045",
   "metadata": {},
   "outputs": [],
   "source": [
    "NRM_train_dict = {window: [] for window in windows}\n",
    "NRM_label = []\n",
    "NRM_train_dict, NRM_label = main_loader(file_dir, windows, 0, NRM_train_dict, NRM_label, target_shape, 2000)\n",
    "NRM_train = stack_slices(NRM_train_dict)\n",
    "\n",
    "EDH_train_dict = {window: [] for window in windows}\n",
    "EDH_label = []\n",
    "EDH_train_dict, EDH_label = main_loader(file_dir, windows, 1, EDH_train_dict, EDH_label, target_shape, filter_set=filtered_files['EPH'])\n",
    "EDH_train = stack_slices(EDH_train_dict)\n",
    "\n",
    "\n",
    "X_train = np.concatenate((NRM_train, EDH_train), axis=0)  # Add other hemorrhage types as needed\n",
    "y_train = np.concatenate((NRM_label, EDH_label), axis=0)\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_valid, y_valid = shuffle(X_valid, y_valid)\n",
    "\n",
    "# Define and compile the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3), input_shape=(256, 256, 4), padding=\"same\"))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\"))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\"))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(256, kernel_size=(3, 3), padding=\"same\"))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dense(7, activation=\"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(), metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
